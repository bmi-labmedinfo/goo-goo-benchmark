{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53778f64",
   "metadata": {},
   "source": [
    "# Tabular Transformer benchmark on Medical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "745d7d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tabpfn import TabPFNClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix, balanced_accuracy_score\n",
    "from sklearn.utils import shuffle\n",
    "from collections import Counter\n",
    "\n",
    "def get_dataset_info(name: str):\n",
    "    for ds in config[\"datasets\"]:\n",
    "        if ds[\"name\"] == name:\n",
    "            return ds\n",
    "    raise ValueError(f\"Dataset '{name}' not found.\")\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else y_pred\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"BalancedAcc\": balanced_accuracy_score(y_test, y_pred),\n",
    "        \"F1\": f1_score(y_test, y_pred),\n",
    "        \"AUC\": roc_auc_score(y_test, y_prob),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8b0fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_classes(y_list, map_classes):\n",
    "    new_y_list = []\n",
    "    for x in y_list:\n",
    "        if x in map_classes.keys():\n",
    "            new_y_list.append(map_classes[x])\n",
    "        else:\n",
    "            new_y_list.append(x)\n",
    "    return new_y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bff3d930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datasets': [{'name': 'myocardial_infarction',\n",
       "   'path': '/Users/giovannanicora/Documents/progetti_in_corso/tabular_fm_medical_benchmark/dataset/myocardial_infarction_complications.csv',\n",
       "   'target': 'class',\n",
       "   'group_class': '1,2,3,4,5,6,7',\n",
       "   'notes': 'UCI Machine Learning repo dataset'},\n",
       "  {'name': 'cdc_diabetes',\n",
       "   'path': '/Users/giovannanicora/Documents/progetti_in_corso/tabular_fm_medical_benchmark/dataset/CDC_diabetes.csv',\n",
       "   'target': 'class',\n",
       "   'notes': 'UCI Machine Learning repo dataset'}]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading yaml file\n",
    "with open(\"/Users/giovannanicora/PycharmProjects/tabular-fm-medical-benchmark/data/dataset_info.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "config\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcc649c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'cdc_diabetes',\n",
       " 'path': '/Users/giovannanicora/Documents/progetti_in_corso/tabular_fm_medical_benchmark/dataset/CDC_diabetes.csv',\n",
       " 'target': 'class',\n",
       " 'notes': 'UCI Machine Learning repo dataset'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a dataset - for instance, myocardial infarction\n",
    "dataset_name = \"cdc_diabetes\"\n",
    "dataset_info = get_dataset_info(dataset_name)\n",
    "dataset_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3358eaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients: 253680\n",
      "Number of features: 22\n",
      "Class # Counter({0: 218334, 1: 35346})\n",
      "Class 1 %,  0.13933301797540207\n"
     ]
    }
   ],
   "source": [
    "# read the dataframe\n",
    "df = pd.read_csv(dataset_info['path'])\n",
    "y = df[dataset_info['target']].tolist()\n",
    "\n",
    "# removing the target variable\n",
    "df = df.drop(columns=dataset_info['target'])\n",
    "\n",
    "# for some multiclass problems, we convert it to binary\n",
    "if 'group_class' in dataset_info.keys():\n",
    "    # grouping class\n",
    "    map_dict = {}\n",
    "    for n in dataset_info['group_class'].split(','):\n",
    "        n_int = int(n.strip())\n",
    "        map_dict[n_int] = 1\n",
    "    \n",
    "    y = group_classes(y, map_dict)\n",
    "\n",
    "# some statistics\n",
    "print(\"Number of patients:\", df.shape[0])\n",
    "print(\"Number of features:\", df.shape[1])\n",
    "print(\"Class #\", Counter(y))\n",
    "print(\"Class 1 %, \", Counter(y)[1]/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e7b2018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "len(y) == df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840e6e1a",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec721f2",
   "metadata": {},
   "source": [
    "## 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5121bfb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#######\n",
      "0\n",
      "Train size: 40 - Test size: 10\n",
      "#######\n",
      "1\n",
      "Train size: 40 - Test size: 10\n",
      "#######\n",
      "2\n",
      "Train size: 40 - Test size: 10\n",
      "#######\n",
      "3\n",
      "Train size: 40 - Test size: 10\n",
      "#######\n",
      "4\n",
      "Train size: 40 - Test size: 10\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "rf_grid = {\n",
    "    \"clf__n_estimators\": [100, 300],\n",
    "    \"clf__max_depth\": [None, 5, 10],\n",
    "    \"clf__min_samples_leaf\": [1, 3, 5],\n",
    "}\n",
    "\n",
    "lasso = LogisticRegression(\n",
    "    solver=\"saga\",\n",
    "    penalty=\"l1\",\n",
    "    max_iter=10000,\n",
    "    random_state=42,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "\n",
    "lasso_grid = {\n",
    "    \"clf__C\": np.logspace(-3, 1, 5),  # inverse of regularization strength\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "n_splits = 5\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "# we will evaluate at an increasing number of training samples\n",
    "n_context = 50\n",
    "i_context = np.random.choice(df.shape[0], size=n_context, replace=False)\n",
    "\n",
    "df_subset = df.iloc[i_context, :]\n",
    "y_subset = np.array(y)[i_context]\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(kf.split(df_subset, y_subset)):\n",
    "\n",
    "    X_train = df_subset.iloc[train_index, :]\n",
    "    y_train = np.array(y_subset)[train_index]\n",
    "\n",
    "\n",
    "    X_test = df_subset.iloc[test_index, :]\n",
    "    y_test = np.array(y_subset)[test_index]\n",
    "\n",
    "    # preprocessing\n",
    "    # 1 - imputation with the most frequent value\n",
    "    imp_mode = SimpleImputer(strategy=\"most_frequent\")\n",
    "    X_train = imp_mode.fit_transform(X_train)\n",
    "    X_test = imp_mode.transform(X_test)\n",
    "\n",
    "    # 2 - normalization (for LR)\n",
    "    # scaler = MinMaxScaler()\n",
    "    # X_train_norm = scaler.fit_transform(X_train)\n",
    "    # X_test_norm = scaler.transform(X_test)\n",
    "    \n",
    "    print(\"#######\")\n",
    "    print(i)\n",
    "    print(\"Train size:\", X_train.shape[0], \"- Test size:\", X_test.shape[0])\n",
    "\n",
    "\n",
    "    # training\n",
    "    inner_cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "    # ---- Random Forest ----\n",
    "    rf_pipe = Pipeline([(\"clf\", rf)])\n",
    "    rf_search = GridSearchCV(\n",
    "        rf_pipe, rf_grid, cv=inner_cv,\n",
    "        scoring=\"balanced_accuracy\", n_jobs=-1\n",
    "    )\n",
    "    rf_search.fit(X_train, y_train)\n",
    "    results.append(evaluate_model(rf_search.best_estimator_, X_test, y_test, \"RandomForest\"))\n",
    "\n",
    "    # ---- LASSO Logistic Regression ----\n",
    "    lasso_pipe = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", lasso)\n",
    "    ])\n",
    "    lasso_search = GridSearchCV(\n",
    "        lasso_pipe, lasso_grid, cv=inner_cv,\n",
    "        scoring=\"balanced_accuracy\", n_jobs=-1\n",
    "    )\n",
    "    lasso_search.fit(X_train, y_train)\n",
    "    results.append(evaluate_model(lasso_search.best_estimator_, X_test, y_test, \"LASSO_Logistic\"))\n",
    "\n",
    "\n",
    "\n",
    "    # 3-TabPFN (no tuning)\n",
    "    tabpfn_class = TabPFNClassifier()\n",
    "    tabpfn_class.fit(X_train, y_train)\n",
    "    results.append(evaluate_model(tabpfn_class, X_test, y_test, \"TabPFN_raw\"))\n",
    "\n",
    "\n",
    "    # 4-TabPFN but with preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e143b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'RandomForest',\n",
       "  'Accuracy': 0.8,\n",
       "  'BalancedAcc': 0.8888888888888888,\n",
       "  'F1': 0.5,\n",
       "  'AUC': 1.0},\n",
       " {'model': 'LASSO_Logistic',\n",
       "  'Accuracy': 0.7,\n",
       "  'BalancedAcc': 0.3888888888888889,\n",
       "  'F1': 0.0,\n",
       "  'AUC': 0.6666666666666667},\n",
       " {'model': 'TabPFN_raw',\n",
       "  'Accuracy': 0.6,\n",
       "  'BalancedAcc': 0.7777777777777778,\n",
       "  'F1': 0.3333333333333333,\n",
       "  'AUC': 0.6666666666666667},\n",
       " {'model': 'RandomForest',\n",
       "  'Accuracy': 0.9,\n",
       "  'BalancedAcc': 0.75,\n",
       "  'F1': 0.6666666666666666,\n",
       "  'AUC': 1.0},\n",
       " {'model': 'LASSO_Logistic',\n",
       "  'Accuracy': 0.9,\n",
       "  'BalancedAcc': 0.75,\n",
       "  'F1': 0.6666666666666666,\n",
       "  'AUC': 0.9375},\n",
       " {'model': 'TabPFN_raw',\n",
       "  'Accuracy': 0.5,\n",
       "  'BalancedAcc': 0.5,\n",
       "  'F1': 0.2857142857142857,\n",
       "  'AUC': 0.25},\n",
       " {'model': 'RandomForest',\n",
       "  'Accuracy': 0.8,\n",
       "  'BalancedAcc': 0.6875,\n",
       "  'F1': 0.5,\n",
       "  'AUC': 0.5625},\n",
       " {'model': 'LASSO_Logistic',\n",
       "  'Accuracy': 0.8,\n",
       "  'BalancedAcc': 0.6875,\n",
       "  'F1': 0.5,\n",
       "  'AUC': 0.625},\n",
       " {'model': 'TabPFN_raw',\n",
       "  'Accuracy': 0.7,\n",
       "  'BalancedAcc': 0.8125,\n",
       "  'F1': 0.5714285714285714,\n",
       "  'AUC': 0.75},\n",
       " {'model': 'RandomForest',\n",
       "  'Accuracy': 0.5,\n",
       "  'BalancedAcc': 0.3125,\n",
       "  'F1': 0.0,\n",
       "  'AUC': 0.375},\n",
       " {'model': 'LASSO_Logistic',\n",
       "  'Accuracy': 0.7,\n",
       "  'BalancedAcc': 0.625,\n",
       "  'F1': 0.4,\n",
       "  'AUC': 0.625},\n",
       " {'model': 'TabPFN_raw',\n",
       "  'Accuracy': 0.5,\n",
       "  'BalancedAcc': 0.5,\n",
       "  'F1': 0.2857142857142857,\n",
       "  'AUC': 0.375},\n",
       " {'model': 'RandomForest',\n",
       "  'Accuracy': 0.7,\n",
       "  'BalancedAcc': 0.4375,\n",
       "  'F1': 0.0,\n",
       "  'AUC': 0.8125},\n",
       " {'model': 'LASSO_Logistic',\n",
       "  'Accuracy': 0.6,\n",
       "  'BalancedAcc': 0.375,\n",
       "  'F1': 0.0,\n",
       "  'AUC': 0.4375},\n",
       " {'model': 'TabPFN_raw',\n",
       "  'Accuracy': 0.3,\n",
       "  'BalancedAcc': 0.1875,\n",
       "  'F1': 0.0,\n",
       "  'AUC': 0.0}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e14c904b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Accuracy        BalancedAcc            F1           AUC       \n",
      "                   mean    std        mean    std   mean    std   mean    std\n",
      "model                                                                        \n",
      "LASSO_Logistic     0.74  0.114       0.565  0.173  0.313  0.301  0.658  0.180\n",
      "RandomForest       0.74  0.152       0.615  0.235  0.333  0.312  0.750  0.276\n",
      "TabPFN_raw         0.52  0.148       0.556  0.253  0.295  0.203  0.408  0.307\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "summary = results_df.groupby(\"model\").agg([\"mean\", \"std\"]).round(3)\n",
    "print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
